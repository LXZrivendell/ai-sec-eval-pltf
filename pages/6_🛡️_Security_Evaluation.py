import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import time
from core.auth_manager import AuthManager
from core.model_loader import ModelLoader
from core.dataset_manager import DatasetManager
from core.attack_manager import AttackManager
from core.security_evaluator import SecurityEvaluator

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å®‰å…¨è¯„ä¼° - AIæ¨¡å‹å®‰å…¨è¯„ä¼°å¹³å°",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# åˆå§‹åŒ–ç®¡ç†å™¨
auth_manager = AuthManager()
model_loader = ModelLoader()
dataset_manager = DatasetManager()
attack_manager = AttackManager()
security_evaluator = SecurityEvaluator()

# æ£€æŸ¥ç™»å½•çŠ¶æ€
if not auth_manager.is_logged_in():
    st.error("âš ï¸ è¯·å…ˆç™»å½•åå†ä½¿ç”¨æ­¤åŠŸèƒ½")
    st.info("ğŸ‘ˆ è¯·ç‚¹å‡»ä¾§è¾¹æ ä¸­çš„ 'ğŸ” Login' è¿›è¡Œç™»å½•")
    st.stop()

# è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
current_user = auth_manager.get_current_user()
user_id = current_user['user_id']
user_role = current_user['role']

# é¡µé¢æ ‡é¢˜
st.title("ğŸ›¡ï¸ AIæ¨¡å‹å®‰å…¨è¯„ä¼°")
st.markdown("---")

# ä¾§è¾¹æ  - åŠŸèƒ½é€‰æ‹©
st.sidebar.header("åŠŸèƒ½é€‰æ‹©")
function_choice = st.sidebar.selectbox(
    "é€‰æ‹©åŠŸèƒ½",
    ["æ–°å»ºè¯„ä¼°", "è¯„ä¼°å†å²", "è¯„ä¼°æŠ¥å‘Š", "è¯„ä¼°ç»Ÿè®¡"]
)

if function_choice == "æ–°å»ºè¯„ä¼°":
    st.header("ğŸ¯ æ–°å»ºå®‰å…¨è¯„ä¼°")
    
    # è¯„ä¼°é…ç½®
    st.subheader("ğŸ“‹ è¯„ä¼°é…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        evaluation_name = st.text_input(
            "è¯„ä¼°åç§°",
            placeholder="è¾“å…¥è¯„ä¼°ä»»åŠ¡åç§°",
            help="ä¸ºæ­¤æ¬¡è¯„ä¼°ä»»åŠ¡èµ·ä¸€ä¸ªæè¿°æ€§çš„åç§°"
        )
        
        evaluation_description = st.text_area(
            "è¯„ä¼°æè¿°",
            placeholder="æè¿°æ­¤æ¬¡è¯„ä¼°çš„ç›®çš„å’Œé¢„æœŸç»“æœ",
            height=100
        )
    
    with col2:
        evaluation_type = st.selectbox(
            "è¯„ä¼°ç±»å‹",
            ["é²æ£’æ€§è¯„ä¼°", "å¯¹æŠ—æ”»å‡»è¯„ä¼°", "ç»¼åˆå®‰å…¨è¯„ä¼°"],
            help="é€‰æ‹©è¯„ä¼°ç±»å‹"
        )
        
        priority = st.selectbox(
            "ä¼˜å…ˆçº§",
            ["ä½", "ä¸­", "é«˜"],
            index=1,
            help="è®¾ç½®è¯„ä¼°ä»»åŠ¡çš„ä¼˜å…ˆçº§"
        )
    
    st.markdown("---")
    
    # æ¨¡å‹é€‰æ‹©
    st.subheader("ğŸ¤– é€‰æ‹©æ¨¡å‹")
    
    # è·å–ç”¨æˆ·æ¨¡å‹
    if user_role == 'admin':
        user_models = model_loader.get_all_models()
    else:
        user_models = model_loader.get_user_models(user_id)
    
    if user_models:
        # å°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼è¿›è¡Œå¤„ç†
        model_list = []
        for model_id, model_info in user_models.items():
            model_data = {
                'id': model_id,
                'name': model_info.get('model_name', 'Unknown'),
                'framework': model_info.get('model_type', 'Unknown'),
                'model_type': model_info.get('model_type', 'Unknown'),
                'file_size': model_info.get('file_size', 0),
                'upload_time': model_info.get('upload_time', ''),
                'uploader': model_info.get('uploaded_by', ''),
                'description': model_info.get('description', ''),
                'file_path': model_info.get('file_path', ''),
                'validation_status': model_info.get('validation_status', 'unknown'),
                'validation_message': model_info.get('validation_message', '')
            }
            model_list.append(model_data)
        
        model_options = {f"{model['name']} ({model['framework']})":
                        model for model in model_list}
        
        selected_model_key = st.selectbox(
            "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹",
            list(model_options.keys()),
            help="é€‰æ‹©ä¸€ä¸ªå·²ä¸Šä¼ çš„æ¨¡å‹è¿›è¡Œå®‰å…¨è¯„ä¼°"
        )
        
        if selected_model_key:
            selected_model = model_options[selected_model_key]
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            with st.expander("ğŸ“Š æ¨¡å‹ä¿¡æ¯", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write(f"**æ¨¡å‹åç§°**: {selected_model['name']}")
                    st.write(f"**æ¡†æ¶**: {selected_model['framework']}")
                    st.write(f"**ç±»å‹**: {selected_model['model_type']}")
                
                with col2:
                    st.write(f"**æ–‡ä»¶å¤§å°**: {selected_model['file_size'] / (1024*1024):.2f} MB")
                    st.write(f"**ä¸Šä¼ æ—¶é—´**: {selected_model['upload_time'][:19]}")
                    st.write(f"**ä¸Šä¼ è€…**: {selected_model['uploader']}")
                
                with col3:
                    if selected_model.get('description'):
                        st.write(f"**æè¿°**: {selected_model['description']}")
                    if selected_model.get('accuracy'):
                        st.write(f"**å‡†ç¡®ç‡**: {selected_model['accuracy']}")
    else:
        st.warning("âš ï¸ æ‚¨è¿˜æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ¨¡å‹")
        st.info("è¯·å…ˆåœ¨ 'ğŸ“¤ Model Upload' é¡µé¢ä¸Šä¼ æ¨¡å‹")
        st.stop()
    
    st.markdown("---")
    
    # æ•°æ®é›†é€‰æ‹©
    st.subheader("ğŸ“Š é€‰æ‹©æ•°æ®é›†")
    
    dataset_source = st.radio(
        "æ•°æ®é›†æ¥æº",
        ["å†…ç½®æ•°æ®é›†", "æˆ‘çš„æ•°æ®é›†"],
        horizontal=True
    )
    
    if dataset_source == "å†…ç½®æ•°æ®é›†":
        builtin_datasets = dataset_manager.get_builtin_datasets()
        
        if builtin_datasets:
            # å°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼è¿›è¡Œå¤„ç†
            dataset_list = []
            for dataset_id, dataset_info in builtin_datasets.items():
                dataset_data = {
                    'id': dataset_id,
                    'name': dataset_info.get('name', 'Unknown'),
                    'type': dataset_info.get('type', 'Unknown'),
                    'data_type': dataset_info.get('data_type', dataset_info.get('type', 'Unknown')),
                    'description': dataset_info.get('description', ''),
                    'file_size': dataset_info.get('file_size', 0),
                    'shape': dataset_info.get('shape', ''),
                    'file_path': dataset_info.get('file_path', '')
                }
                dataset_list.append(dataset_data)
            
            dataset_options = {f"{ds['name']} ({ds['type']})":
                             ds for ds in dataset_list}
            
            selected_dataset_key = st.selectbox(
                "é€‰æ‹©å†…ç½®æ•°æ®é›†",
                list(dataset_options.keys()),
                help="é€‰æ‹©ä¸€ä¸ªå†…ç½®æ•°æ®é›†è¿›è¡Œè¯„ä¼°"
            )
            
            if selected_dataset_key:
                selected_dataset = dataset_options[selected_dataset_key]
        else:
            st.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å†…ç½®æ•°æ®é›†")
            st.stop()
    
    else:  # æˆ‘çš„æ•°æ®é›†
        if user_role == 'admin':
            user_datasets = dataset_manager.get_all_datasets()
        else:
            user_datasets = dataset_manager.get_user_datasets(user_id)
        
        if user_datasets:
            # å°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼è¿›è¡Œå¤„ç†
            dataset_list = []
            for dataset_id, dataset_info in user_datasets.items():
                dataset_data = {
                    'id': dataset_id,
                    'name': dataset_info.get('name', 'Unknown'),
                    'data_type': dataset_info.get('data_type', dataset_info.get('type', 'Unknown')),
                    'description': dataset_info.get('description', ''),
                    'file_size': dataset_info.get('file_size', 0),
                    'shape': dataset_info.get('shape', ''),
                    'file_path': dataset_info.get('file_path', '')
                }
                dataset_list.append(dataset_data)
            
            dataset_options = {f"{ds['name']} ({ds['data_type']})":
                             ds for ds in dataset_list}
            
            selected_dataset_key = st.selectbox(
                "é€‰æ‹©æˆ‘çš„æ•°æ®é›†",
                list(dataset_options.keys()),
                help="é€‰æ‹©ä¸€ä¸ªå·²ä¸Šä¼ çš„æ•°æ®é›†è¿›è¡Œè¯„ä¼°"
            )
            
            if selected_dataset_key:
                selected_dataset = dataset_options[selected_dataset_key]
        else:
            st.warning("âš ï¸ æ‚¨è¿˜æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ•°æ®é›†")
            st.info("è¯·å…ˆåœ¨ 'ğŸ“Š Dataset Manager' é¡µé¢ä¸Šä¼ æ•°æ®é›†")
            st.stop()
    
    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
    if 'selected_dataset' in locals():
        with st.expander("ğŸ“‹ æ•°æ®é›†ä¿¡æ¯", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**æ•°æ®é›†åç§°**: {selected_dataset['name']}")
                st.write(f"**æ•°æ®ç±»å‹**: {selected_dataset.get('data_type', 'N/A')}")
                if 'shape' in selected_dataset:
                    st.write(f"**æ•°æ®å½¢çŠ¶**: {selected_dataset['shape']}")
            
            with col2:
                if 'description' in selected_dataset:
                    st.write(f"**æè¿°**: {selected_dataset['description']}")
                if 'file_size' in selected_dataset:
                    st.write(f"**æ–‡ä»¶å¤§å°**: {selected_dataset['file_size'] / (1024*1024):.2f} MB")
    
    st.markdown("---")
    
    # æ”»å‡»é…ç½®é€‰æ‹©
    st.subheader("âš”ï¸ é€‰æ‹©æ”»å‡»é…ç½®")
    
    # è·å–ç”¨æˆ·æ”»å‡»é…ç½®
    user_configs = attack_manager.get_user_configs(user_id)
    
    if user_configs:
        config_options = {f"{config['name']} ({config['config']['algorithm']})":
                         config for config in user_configs}
        
        selected_configs = st.multiselect(
            "é€‰æ‹©æ”»å‡»é…ç½®",
            list(config_options.keys()),
            help="å¯ä»¥é€‰æ‹©å¤šä¸ªæ”»å‡»é…ç½®è¿›è¡Œç»¼åˆè¯„ä¼°"
        )
        
        if selected_configs:
            # æ˜¾ç¤ºé€‰ä¸­çš„é…ç½®ä¿¡æ¯
            with st.expander("ğŸ”§ é€‰ä¸­çš„æ”»å‡»é…ç½®", expanded=False):
                for config_key in selected_configs:
                    config = config_options[config_key]
                    st.write(f"**{config['name']}**")
                    st.write(f"- ç®—æ³•: {config['config']['algorithm']} ({config['config']['algorithm_name']})")
                    st.write(f"- ç±»å‹: {config['config']['attack_type']}")
                    st.write(f"- æè¿°: {config['config'].get('description', 'æ— æè¿°')}")
                    st.markdown("---")
    else:
        st.warning("âš ï¸ æ‚¨è¿˜æ²¡æœ‰åˆ›å»ºä»»ä½•æ”»å‡»é…ç½®")
        st.info("è¯·å…ˆåœ¨ 'âš”ï¸ Attack Config' é¡µé¢åˆ›å»ºæ”»å‡»é…ç½®")
        st.stop()
    
    # è¯„ä¼°å‚æ•°
    st.subheader("âš™ï¸ è¯„ä¼°å‚æ•°")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        sample_size = st.number_input(
            "æ ·æœ¬æ•°é‡",
            value=100,
            min_value=10,
            max_value=10000,
            step=10,
            help="ç”¨äºè¯„ä¼°çš„æ ·æœ¬æ•°é‡"
        )
        
        batch_size = st.number_input(
            "æ‰¹å¤„ç†å¤§å°",
            value=32,
            min_value=1,
            max_value=512,
            step=1,
            help="è¯„ä¼°æ—¶çš„æ‰¹å¤„ç†å¤§å°"
        )
    
    with col2:
        confidence_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.01,
            help="åˆ†ç±»ç½®ä¿¡åº¦é˜ˆå€¼"
        )
        
        max_iterations = st.number_input(
            "æœ€å¤§è¿­ä»£æ¬¡æ•°",
            value=1000,
            min_value=100,
            max_value=10000,
            step=100,
            help="æ”»å‡»ç®—æ³•çš„æœ€å¤§è¿­ä»£æ¬¡æ•°"
        )
    
    with col3:
        save_results = st.checkbox(
            "ä¿å­˜è¯¦ç»†ç»“æœ",
            value=True,
            help="æ˜¯å¦ä¿å­˜è¯¦ç»†çš„è¯„ä¼°ç»“æœ"
        )
        
        generate_report = st.checkbox(
            "ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š",
            value=True,
            help="æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"
        )
    
    # å¼€å§‹è¯„ä¼°
    st.markdown("---")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button("ğŸš€ å¼€å§‹å®‰å…¨è¯„ä¼°", type="primary", use_container_width=True):
            if not evaluation_name:
                st.error("è¯·è¾“å…¥è¯„ä¼°åç§°")
            elif not selected_configs:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ”»å‡»é…ç½®")
            else:
                # åˆ›å»ºè¯„ä¼°ä»»åŠ¡
                evaluation_config = {
                    "name": evaluation_name,
                    "description": evaluation_description,
                    "type": evaluation_type,
                    "priority": priority,
                    "model": selected_model,
                    "dataset": selected_dataset,
                    "attack_configs": [config_options[key] for key in selected_configs],
                    "parameters": {
                        "sample_size": sample_size,
                        "batch_size": batch_size,
                        "confidence_threshold": confidence_threshold,
                        "max_iterations": max_iterations,
                        "save_results": save_results,
                        "generate_report": generate_report
                    },
                    "user_id": user_id,
                    "created_at": datetime.now().isoformat()
                }
                
                # å¼€å§‹è¯„ä¼°
                with st.spinner("æ­£åœ¨å¯åŠ¨å®‰å…¨è¯„ä¼°..."):
                    evaluation_id = security_evaluator.start_evaluation(evaluation_config)
                    
                    if evaluation_id:
                        st.success(f"âœ… è¯„ä¼°ä»»åŠ¡å·²å¯åŠ¨ï¼ä»»åŠ¡ID: {evaluation_id}")
                        st.info("ğŸ“Š æ‚¨å¯ä»¥åœ¨ 'è¯„ä¼°å†å²' ä¸­æŸ¥çœ‹è¯„ä¼°è¿›åº¦å’Œç»“æœ")
                        st.balloons()
                        
                        # æ˜¾ç¤ºè¯„ä¼°è¿›åº¦
                        progress_placeholder = st.empty()
                        status_placeholder = st.empty()
                        
                        # æ¨¡æ‹Ÿè¯„ä¼°è¿›åº¦ï¼ˆå®é™…åº”è¯¥ä»evaluatorè·å–ï¼‰
                        for i in range(101):
                            progress_placeholder.progress(i)
                            if i < 20:
                                status_placeholder.info("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹å’Œæ•°æ®é›†...")
                            elif i < 40:
                                status_placeholder.info("âš”ï¸ æ­£åœ¨æ‰§è¡Œæ”»å‡»ç®—æ³•...")
                            elif i < 80:
                                status_placeholder.info("ğŸ“Š æ­£åœ¨è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
                            elif i < 100:
                                status_placeholder.info("ğŸ“ æ­£åœ¨ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
                            else:
                                status_placeholder.success("âœ… è¯„ä¼°å®Œæˆï¼")
                            
                            time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                        
                        st.success("ğŸ‰ å®‰å…¨è¯„ä¼°å·²å®Œæˆï¼")
                    else:
                        st.error("âŒ è¯„ä¼°ä»»åŠ¡å¯åŠ¨å¤±è´¥")

elif function_choice == "è¯„ä¼°å†å²":
    st.header("ğŸ“š è¯„ä¼°å†å²")
    
    # è·å–ç”¨æˆ·è¯„ä¼°å†å²
    if user_role == 'admin':
        evaluations = security_evaluator.get_all_evaluations()
    else:
        evaluations = security_evaluator.get_user_evaluations(user_id)
    
    if evaluations:
        # æœç´¢å’Œç­›é€‰
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            search_term = st.text_input(
                "ğŸ” æœç´¢è¯„ä¼°",
                placeholder="è¾“å…¥è¯„ä¼°åç§°æˆ–æè¿°å…³é”®è¯"
            )
        
        with col2:
            status_filter = st.selectbox(
                "çŠ¶æ€ç­›é€‰",
                ["å…¨éƒ¨", "è¿è¡Œä¸­", "å·²å®Œæˆ", "å¤±è´¥", "å·²å–æ¶ˆ"]
            )
        
        with col3:
            sort_by = st.selectbox(
                "æ’åºæ–¹å¼",
                ["åˆ›å»ºæ—¶é—´", "å®Œæˆæ—¶é—´", "è¯„ä¼°åç§°", "çŠ¶æ€"]
            )
        
        # ç­›é€‰è¯„ä¼°
        filtered_evaluations = evaluations
        
        if search_term:
            filtered_evaluations = [
                eval for eval in filtered_evaluations
                if search_term.lower() in eval['name'].lower() or
                   search_term.lower() in eval.get('description', '').lower()
            ]
        
        if status_filter != "å…¨éƒ¨":
            filtered_evaluations = [
                eval for eval in filtered_evaluations
                if eval['status'] == status_filter
            ]
        
        # æ’åº
        if sort_by == "åˆ›å»ºæ—¶é—´":
            filtered_evaluations.sort(key=lambda x: x['created_at'], reverse=True)
        elif sort_by == "å®Œæˆæ—¶é—´":
            filtered_evaluations.sort(key=lambda x: x.get('completed_at', ''), reverse=True)
        elif sort_by == "è¯„ä¼°åç§°":
            filtered_evaluations.sort(key=lambda x: x['name'])
        else:  # çŠ¶æ€
            filtered_evaluations.sort(key=lambda x: x['status'])
        
        st.markdown(f"**æ‰¾åˆ° {len(filtered_evaluations)} ä¸ªè¯„ä¼°è®°å½•**")
        
        # æ˜¾ç¤ºè¯„ä¼°åˆ—è¡¨
        for i, evaluation in enumerate(filtered_evaluations):
            status_color = {
                "è¿è¡Œä¸­": "ğŸ”„",
                "å·²å®Œæˆ": "âœ…",
                "å¤±è´¥": "âŒ",
                "å·²å–æ¶ˆ": "â¹ï¸"
            }.get(evaluation['status'], "â“")
            
            with st.expander(
                f"{status_color} {evaluation['name']} - {evaluation['type']}",
                expanded=False
            ):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.write(f"**è¯„ä¼°ID**: {evaluation['id']}")
                    st.write(f"**ç±»å‹**: {evaluation['type']}")
                    st.write(f"**çŠ¶æ€**: {evaluation['status']}")
                    st.write(f"**æè¿°**: {evaluation.get('description', 'æ— æè¿°')}")
                    st.write(f"**åˆ›å»ºæ—¶é—´**: {evaluation['created_at'][:19]}")
                    
                    if evaluation.get('completed_at'):
                        st.write(f"**å®Œæˆæ—¶é—´**: {evaluation['completed_at'][:19]}")
                    
                    # æ˜¾ç¤ºè¯„ä¼°é…ç½®
                    if evaluation.get('config'):
                        st.write(f"**æ¨¡å‹**: {evaluation['config']['model']['name']}")
                        st.write(f"**æ•°æ®é›†**: {evaluation['config']['dataset']['name']}")
                        st.write(f"**æ”»å‡»é…ç½®æ•°**: {len(evaluation['config']['attack_configs'])}")
                
                with col2:
                    st.write("**æ“ä½œ**")
                    
                    # æŸ¥çœ‹è¯¦æƒ…
                    if st.button(f"ğŸ‘ï¸ æŸ¥çœ‹è¯¦æƒ…", key=f"view_{i}"):
                        st.session_state[f"show_details_{i}"] = True
                    
                    # ä¸‹è½½æŠ¥å‘Š
                    if evaluation['status'] == 'å·²å®Œæˆ':
                        if st.button(f"ğŸ“¥ ä¸‹è½½æŠ¥å‘Š", key=f"download_{i}"):
                            st.info("æŠ¥å‘Šä¸‹è½½åŠŸèƒ½å¼€å‘ä¸­...")
                    
                    # é‡æ–°è¿è¡Œ
                    if evaluation['status'] in ['å¤±è´¥', 'å·²å–æ¶ˆ']:
                        if st.button(f"ğŸ”„ é‡æ–°è¿è¡Œ", key=f"rerun_{i}"):
                            st.info("é‡æ–°è¿è¡ŒåŠŸèƒ½å¼€å‘ä¸­...")
                    
                    # åˆ é™¤è¯„ä¼°
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{i}", type="secondary"):
                        if security_evaluator.delete_evaluation(evaluation['id'], user_id):
                            st.success("è¯„ä¼°è®°å½•åˆ é™¤æˆåŠŸï¼")
                            st.rerun()
                        else:
                            st.error("è¯„ä¼°è®°å½•åˆ é™¤å¤±è´¥")
                
                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                if st.session_state.get(f"show_details_{i}", False):
                    st.markdown("**è¯¦ç»†ä¿¡æ¯**")
                    
                    if evaluation.get('results'):
                        results = evaluation['results']
                        
                        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                        metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
                        
                        with metrics_col1:
                            st.metric(
                                "åŸå§‹å‡†ç¡®ç‡",
                                f"{results.get('original_accuracy', 0):.2%}"
                            )
                        
                        with metrics_col2:
                            st.metric(
                                "æ”»å‡»æˆåŠŸç‡",
                                f"{results.get('attack_success_rate', 0):.2%}"
                            )
                        
                        with metrics_col3:
                            st.metric(
                                "é²æ£’æ€§å¾—åˆ†",
                                f"{results.get('robustness_score', 0):.2f}"
                            )
                        
                        # æ˜¾ç¤ºæ”»å‡»ç»“æœå›¾è¡¨
                        if results.get('attack_results'):
                            attack_data = []
                            for attack_name, attack_result in results['attack_results'].items():
                                attack_data.append({
                                    "æ”»å‡»ç®—æ³•": attack_name,
                                    "æˆåŠŸç‡": attack_result.get('success_rate', 0),
                                    "å¹³å‡æ‰°åŠ¨": attack_result.get('avg_perturbation', 0)
                                })
                            
                            if attack_data:
                                attack_df = pd.DataFrame(attack_data)
                                
                                fig = px.bar(
                                    attack_df,
                                    x="æ”»å‡»ç®—æ³•",
                                    y="æˆåŠŸç‡",
                                    title="å„æ”»å‡»ç®—æ³•æˆåŠŸç‡å¯¹æ¯”"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                    
                    if st.button(f"âŒ å…³é—­è¯¦æƒ…", key=f"close_{i}"):
                        st.session_state[f"show_details_{i}"] = False
                        st.rerun()
    else:
        st.info("ğŸ“ æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œä»»ä½•å®‰å…¨è¯„ä¼°")
        st.markdown("ç‚¹å‡»ä¸Šæ–¹çš„ **æ–°å»ºè¯„ä¼°** å¼€å§‹æ‚¨çš„ç¬¬ä¸€æ¬¡å®‰å…¨è¯„ä¼°ï¼")

elif function_choice == "è¯„ä¼°æŠ¥å‘Š":
    st.header("ğŸ“Š è¯„ä¼°æŠ¥å‘Š")
    
    # è·å–å·²å®Œæˆçš„è¯„ä¼°
    if user_role == 'admin':
        completed_evaluations = security_evaluator.get_completed_evaluations()
    else:
        completed_evaluations = security_evaluator.get_user_completed_evaluations(user_id)
    
    if completed_evaluations:
        # é€‰æ‹©è¯„ä¼°æŠ¥å‘Š
        evaluation_options = {f"{eval['name']} ({eval['completed_at'][:19]})":
                            eval for eval in completed_evaluations}
        
        selected_eval_key = st.selectbox(
            "é€‰æ‹©è¯„ä¼°æŠ¥å‘Š",
            list(evaluation_options.keys()),
            help="é€‰æ‹©ä¸€ä¸ªå·²å®Œæˆçš„è¯„ä¼°æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š"
        )
        
        if selected_eval_key:
            selected_evaluation = evaluation_options[selected_eval_key]
            
            # æ˜¾ç¤ºæŠ¥å‘Šæ ‡é¢˜
            st.markdown(f"## ğŸ“‹ {selected_evaluation['name']} - å®‰å…¨è¯„ä¼°æŠ¥å‘Š")
            st.markdown(f"**è¯„ä¼°æ—¶é—´**: {selected_evaluation['completed_at'][:19]}")
            st.markdown(f"**è¯„ä¼°ç±»å‹**: {selected_evaluation['type']}")
            st.markdown("---")
            
            if selected_evaluation.get('results'):
                results = selected_evaluation['results']
                
                # æ‰§è¡Œæ‘˜è¦
                st.subheader("ğŸ“ˆ æ‰§è¡Œæ‘˜è¦")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "åŸå§‹å‡†ç¡®ç‡",
                        f"{results.get('original_accuracy', 0):.2%}",
                        help="æ¨¡å‹åœ¨åŸå§‹æ•°æ®ä¸Šçš„å‡†ç¡®ç‡"
                    )
                
                with col2:
                    st.metric(
                        "å¹³å‡æ”»å‡»æˆåŠŸç‡",
                        f"{results.get('attack_success_rate', 0):.2%}",
                        help="æ‰€æœ‰æ”»å‡»ç®—æ³•çš„å¹³å‡æˆåŠŸç‡"
                    )
                
                with col3:
                    st.metric(
                        "é²æ£’æ€§å¾—åˆ†",
                        f"{results.get('robustness_score', 0):.2f}",
                        help="æ¨¡å‹çš„æ•´ä½“é²æ£’æ€§è¯„åˆ†"
                    )
                
                with col4:
                    st.metric(
                        "å®‰å…¨ç­‰çº§",
                        results.get('security_level', 'N/A'),
                        help="åŸºäºè¯„ä¼°ç»“æœçš„å®‰å…¨ç­‰çº§"
                    )
                
                # è¯¦ç»†åˆ†æ
                st.subheader("ğŸ” è¯¦ç»†åˆ†æ")
                
                # æ”»å‡»ç»“æœåˆ†æ
                if results.get('attack_results'):
                    st.write("**å„æ”»å‡»ç®—æ³•ç»“æœ**")
                    
                    attack_data = []
                    for attack_name, attack_result in results['attack_results'].items():
                        attack_data.append({
                            "æ”»å‡»ç®—æ³•": attack_name,
                            "æˆåŠŸç‡": f"{attack_result.get('success_rate', 0):.2%}",
                            "å¹³å‡æ‰°åŠ¨": f"{attack_result.get('avg_perturbation', 0):.4f}",
                            "å¹³å‡æŸ¥è¯¢æ¬¡æ•°": attack_result.get('avg_queries', 'N/A'),
                            "å¹³å‡æ—¶é—´(ç§’)": f"{attack_result.get('avg_time', 0):.2f}"
                        })
                    
                    attack_df = pd.DataFrame(attack_data)
                    st.dataframe(attack_df, use_container_width=True)
                    
                    # å¯è§†åŒ–å›¾è¡¨
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # æˆåŠŸç‡å¯¹æ¯”å›¾
                        success_rates = [float(rate.strip('%'))/100 for rate in attack_df['æˆåŠŸç‡']]
                        fig1 = px.bar(
                            x=attack_df['æ”»å‡»ç®—æ³•'],
                            y=success_rates,
                            title="æ”»å‡»æˆåŠŸç‡å¯¹æ¯”",
                            labels={'x': 'æ”»å‡»ç®—æ³•', 'y': 'æˆåŠŸç‡'}
                        )
                        st.plotly_chart(fig1, use_container_width=True)
                    
                    with col2:
                        # æ‰°åŠ¨å¤§å°å¯¹æ¯”å›¾
                        perturbations = [float(pert) for pert in attack_df['å¹³å‡æ‰°åŠ¨']]
                        fig2 = px.bar(
                            x=attack_df['æ”»å‡»ç®—æ³•'],
                            y=perturbations,
                            title="å¹³å‡æ‰°åŠ¨å¤§å°å¯¹æ¯”",
                            labels={'x': 'æ”»å‡»ç®—æ³•', 'y': 'å¹³å‡æ‰°åŠ¨'}
                        )
                        st.plotly_chart(fig2, use_container_width=True)
                
                # å®‰å…¨å»ºè®®
                st.subheader("ğŸ’¡ å®‰å…¨å»ºè®®")
                
                if results.get('recommendations'):
                    for i, recommendation in enumerate(results['recommendations'], 1):
                        st.write(f"{i}. {recommendation}")
                else:
                    # åŸºäºç»“æœç”Ÿæˆå»ºè®®
                    recommendations = []
                    
                    if results.get('attack_success_rate', 0) > 0.5:
                        recommendations.append("æ¨¡å‹å¯¹å¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§è¾ƒå·®ï¼Œå»ºè®®è¿›è¡Œå¯¹æŠ—è®­ç»ƒ")
                    
                    if results.get('robustness_score', 0) < 0.7:
                        recommendations.append("å»ºè®®ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯æé«˜æ¨¡å‹é²æ£’æ€§")
                    
                    recommendations.append("å®šæœŸè¿›è¡Œå®‰å…¨è¯„ä¼°ï¼Œç›‘æ§æ¨¡å‹å®‰å…¨æ€§")
                    recommendations.append("è€ƒè™‘éƒ¨ç½²æ”»å‡»æ£€æµ‹æœºåˆ¶")
                    
                    for i, rec in enumerate(recommendations, 1):
                        st.write(f"{i}. {rec}")
                
                # å¯¼å‡ºæŠ¥å‘Š
                st.markdown("---")
                col1, col2, col3 = st.columns([1, 1, 1])
                
                with col2:
                    report_data = {
                        "evaluation_info": {
                            "name": selected_evaluation['name'],
                            "type": selected_evaluation['type'],
                            "completed_at": selected_evaluation['completed_at']
                        },
                        "results": results,
                        "generated_at": datetime.now().isoformat()
                    }
                    
                    report_json = json.dumps(report_data, ensure_ascii=False, indent=2)
                    
                    st.download_button(
                        label="ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š (JSON)",
                        data=report_json,
                        file_name=f"{selected_evaluation['name']}_report.json",
                        mime="application/json",
                        use_container_width=True
                    )
            else:
                st.warning("âš ï¸ è¯¥è¯„ä¼°æ²¡æœ‰å¯ç”¨çš„ç»“æœæ•°æ®")
    else:
        st.info("ğŸ“ æ²¡æœ‰å·²å®Œæˆçš„è¯„ä¼°æŠ¥å‘Š")
        st.markdown("å®Œæˆå®‰å…¨è¯„ä¼°åï¼ŒæŠ¥å‘Šå°†åœ¨æ­¤å¤„æ˜¾ç¤º")

elif function_choice == "è¯„ä¼°ç»Ÿè®¡":
    st.header("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    
    # è·å–ç»Ÿè®¡æ•°æ®
    stats = security_evaluator.get_evaluation_stats()
    
    # æ€»ä½“ç»Ÿè®¡
    st.subheader("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ€»è¯„ä¼°æ•°",
            stats.get('total_evaluations', 0),
            help="ç³»ç»Ÿä¸­æ‰€æœ‰è¯„ä¼°ä»»åŠ¡çš„æ€»æ•°"
        )
    
    with col2:
        st.metric(
            "å·²å®Œæˆè¯„ä¼°",
            stats.get('completed_evaluations', 0),
            help="å·²æˆåŠŸå®Œæˆçš„è¯„ä¼°ä»»åŠ¡æ•°"
        )
    
    with col3:
        st.metric(
            "è¿è¡Œä¸­è¯„ä¼°",
            stats.get('running_evaluations', 0),
            help="å½“å‰æ­£åœ¨è¿è¡Œçš„è¯„ä¼°ä»»åŠ¡æ•°"
        )
    
    with col4:
        completion_rate = 0
        if stats.get('total_evaluations', 0) > 0:
            completion_rate = stats.get('completed_evaluations', 0) / stats.get('total_evaluations', 0)
        
        st.metric(
            "å®Œæˆç‡",
            f"{completion_rate:.1%}",
            help="è¯„ä¼°ä»»åŠ¡çš„å®Œæˆç‡"
        )
    
    # è¯„ä¼°ç±»å‹åˆ†å¸ƒ
    if stats.get('evaluation_types'):
        st.subheader("ğŸ“Š è¯„ä¼°ç±»å‹åˆ†å¸ƒ")
        
        type_data = list(stats['evaluation_types'].items())
        type_df = pd.DataFrame(type_data, columns=['è¯„ä¼°ç±»å‹', 'æ•°é‡'])
        
        fig = px.pie(
            type_df,
            values='æ•°é‡',
            names='è¯„ä¼°ç±»å‹',
            title="è¯„ä¼°ç±»å‹åˆ†å¸ƒ"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # ç”¨æˆ·æ´»è·ƒåº¦ç»Ÿè®¡
    if user_role == 'admin' and stats.get('user_activity'):
        st.subheader("ğŸ‘¥ ç”¨æˆ·æ´»è·ƒåº¦")
        
        user_data = []
        for user_id, activity in stats['user_activity'].items():
            user_data.append({
                "ç”¨æˆ·ID": user_id,
                "è¯„ä¼°æ€»æ•°": activity.get('total', 0),
                "å·²å®Œæˆ": activity.get('completed', 0),
                "è¿è¡Œä¸­": activity.get('running', 0),
                "å¤±è´¥": activity.get('failed', 0)
            })
        
        user_df = pd.DataFrame(user_data)
        st.dataframe(user_df, use_container_width=True)
    
    # ä¸ªäººç»Ÿè®¡
    st.subheader("ğŸ‘¤ æˆ‘çš„è¯„ä¼°ç»Ÿè®¡")
    
    user_evaluations = security_evaluator.get_user_evaluations(user_id)
    
    if user_evaluations:
        # çŠ¶æ€ç»Ÿè®¡
        status_counts = {}
        type_counts = {}
        
        for evaluation in user_evaluations:
            status = evaluation['status']
            eval_type = evaluation['type']
            
            status_counts[status] = status_counts.get(status, 0) + 1
            type_counts[eval_type] = type_counts.get(eval_type, 0) + 1
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æŒ‰çŠ¶æ€ç»Ÿè®¡**")
            status_df = pd.DataFrame([
                {"çŠ¶æ€": k, "æ•°é‡": v}
                for k, v in status_counts.items()
            ])
            st.dataframe(status_df, use_container_width=True)
        
        with col2:
            st.write("**æŒ‰ç±»å‹ç»Ÿè®¡**")
            type_df = pd.DataFrame([
                {"è¯„ä¼°ç±»å‹": k, "æ•°é‡": v}
                for k, v in type_counts.items()
            ])
            st.dataframe(type_df, use_container_width=True)
        
        # æ—¶é—´è¶‹åŠ¿
        st.write("**è¯„ä¼°æ—¶é—´è¶‹åŠ¿**")
        
        # æŒ‰æœˆç»Ÿè®¡
        monthly_counts = {}
        for evaluation in user_evaluations:
            month = evaluation['created_at'][:7]  # YYYY-MM
            monthly_counts[month] = monthly_counts.get(month, 0) + 1
        
        if monthly_counts:
            months = sorted(monthly_counts.keys())
            counts = [monthly_counts[month] for month in months]
            
            fig = px.line(
                x=months,
                y=counts,
                title="æ¯æœˆè¯„ä¼°æ•°é‡è¶‹åŠ¿",
                labels={'x': 'æœˆä»½', 'y': 'è¯„ä¼°æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("æ‚¨è¿˜æ²¡æœ‰è¿›è¡Œä»»ä½•è¯„ä¼°")

# é¡µé¢åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <small>ğŸ›¡ï¸ æç¤ºï¼šå®‰å…¨è¯„ä¼°æ˜¯æ£€éªŒAIæ¨¡å‹é²æ£’æ€§å’Œå®‰å…¨æ€§çš„é‡è¦æ‰‹æ®µï¼Œå»ºè®®å®šæœŸè¿›è¡Œè¯„ä¼°</small>
    </div>
    """,
    unsafe_allow_html=True
)