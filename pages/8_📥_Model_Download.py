import streamlit as st
import sys
from pathlib import Path
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from core.model_downloader import ModelDownloader
from core.auth_manager import AuthManager

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨¡å‹ä¸‹è½½ - AIæ¨¡å‹å®‰å…¨è¯„ä¼°å¹³å°",
    page_icon="ğŸ“¥",
    layout="wide"
)

# åˆå§‹åŒ–
auth_manager = AuthManager()
model_downloader = ModelDownloader()

# æ£€æŸ¥ç™»å½•çŠ¶æ€
if not st.session_state.get('logged_in', False):
    st.error("âŒ è¯·å…ˆç™»å½•")
    st.stop()

def main():
    st.markdown("# ğŸ“¥ å®˜æ–¹æ¨¡å‹ä¸‹è½½")
    
    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ“Š ä¸‹è½½ç»Ÿè®¡")
        downloaded_models = model_downloader.list_downloaded_models()
        st.metric("å·²ä¸‹è½½æ¨¡å‹", len(downloaded_models))
        
        total_size = sum(info.get('total_size', 0) for info in downloaded_models.values())
        st.metric("æ€»å­˜å‚¨å¤§å°", f"{total_size / (1024*1024*1024):.2f} GB")
    
    # ä¸»è¦é€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["ğŸ”½ ä¸‹è½½æ¨¡å‹", "ğŸ“‹ å·²ä¸‹è½½æ¨¡å‹", "ğŸŒŸ çƒ­é—¨æ¨¡å‹"])
    
    with tab1:
        download_interface()
    
    with tab2:
        downloaded_models_interface()
    
    with tab3:
        popular_models_interface()

def download_interface():
    """æ¨¡å‹ä¸‹è½½ç•Œé¢"""
    st.markdown("## ğŸ”½ ä¸‹è½½æ–°æ¨¡å‹")
    
    # é€‰æ‹©ä¸‹è½½æº
    source = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æº",
        options=["huggingface", "tensorflow_hub", "pytorch_hub", "custom_url"],
        format_func=lambda x: {
            "huggingface": "ğŸ¤— Hugging Face Hub",
            "tensorflow_hub": "ğŸ”¥ TensorFlow Hub", 
            "pytorch_hub": "âš¡ PyTorch Hub",
            "custom_url": "ğŸ”— è‡ªå®šä¹‰ URL"
        }[x]
    )
    
    if source == "huggingface":
        huggingface_download_form()
    elif source == "tensorflow_hub":
        tensorflow_hub_download_form()
    elif source == "pytorch_hub":
        pytorch_hub_download_form()
    elif source == "custom_url":
        custom_url_download_form()

def huggingface_download_form():
    """Hugging Face ä¸‹è½½è¡¨å•"""
    st.markdown("### ğŸ¤— Hugging Face Hub")
    
    with st.form("hf_download_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            model_name = st.text_input(
                "æ¨¡å‹åç§°", 
                placeholder="ä¾‹å¦‚: bert-base-uncased",
                help="è¾“å…¥ Hugging Face Hub ä¸Šçš„æ¨¡å‹åç§°"
            )
            
        with col2:
            model_alias = st.text_input(
                "æœ¬åœ°åˆ«å", 
                placeholder="ä¾‹å¦‚: bert_base",
                help="ä¸ºæ¨¡å‹è®¾ç½®ä¸€ä¸ªæœ¬åœ°åˆ«å"
            )
        
        include_tokenizer = st.checkbox("åŒ…å« Tokenizer", value=True)
        
        if st.form_submit_button("ğŸš€ å¼€å§‹ä¸‹è½½", use_container_width=True):
            if not model_name:
                st.error("âŒ è¯·è¾“å…¥æ¨¡å‹åç§°")
                return
            
            with st.spinner(f"æ­£åœ¨ä¸‹è½½ {model_name}..."):
                success, message, model_id = model_downloader.download_huggingface_model(
                    model_name, model_alias, include_tokenizer
                )
                
                if success:
                    st.success(f"âœ… {message}")
                    st.balloons()
                else:
                    st.error(f"âŒ {message}")

def tensorflow_hub_download_form():
    """TensorFlow Hub ä¸‹è½½è¡¨å•"""
    st.markdown("### ğŸ”¥ TensorFlow Hub")
    
    with st.form("tfhub_download_form"):
        model_url = st.text_input(
            "æ¨¡å‹ URL", 
            placeholder="ä¾‹å¦‚: https://tfhub.dev/google/universal-sentence-encoder/4",
            help="è¾“å…¥ TensorFlow Hub æ¨¡å‹çš„å®Œæ•´ URL"
        )
        
        model_alias = st.text_input(
            "æœ¬åœ°åˆ«å", 
            placeholder="ä¾‹å¦‚: universal_sentence_encoder",
            help="ä¸ºæ¨¡å‹è®¾ç½®ä¸€ä¸ªæœ¬åœ°åˆ«å"
        )
        
        if st.form_submit_button("ğŸš€ å¼€å§‹ä¸‹è½½", use_container_width=True):
            if not model_url or not model_alias:
                st.error("âŒ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
                return
            
            with st.spinner(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹..."):
                success, message, model_id = model_downloader.download_tensorflow_hub_model(
                    model_url, model_alias
                )
                
                if success:
                    st.success(f"âœ… {message}")
                    st.balloons()
                else:
                    st.error(f"âŒ {message}")

def pytorch_hub_download_form():
    """PyTorch Hub ä¸‹è½½è¡¨å•"""
    st.markdown("### âš¡ PyTorch Hub")
    
    with st.form("pytorch_download_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            repo = st.text_input(
                "ä»“åº“", 
                placeholder="ä¾‹å¦‚: pytorch/vision:v0.10.0",
                help="è¾“å…¥ PyTorch Hub ä»“åº“åç§°"
            )
            
        with col2:
            model_name = st.text_input(
                "æ¨¡å‹åç§°", 
                placeholder="ä¾‹å¦‚: resnet18",
                help="è¾“å…¥æ¨¡å‹åç§°"
            )
        
        model_alias = st.text_input(
            "æœ¬åœ°åˆ«å", 
            placeholder="ä¾‹å¦‚: resnet18_pretrained"
        )
        
        pretrained = st.checkbox("ä½¿ç”¨é¢„è®­ç»ƒæƒé‡", value=True)
        
        if st.form_submit_button("ğŸš€ å¼€å§‹ä¸‹è½½", use_container_width=True):
            if not repo or not model_name:
                st.error("âŒ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
                return
            
            # æ£€æŸ¥torchåº“æ˜¯å¦å¯ç”¨
            try:
                import torch
                st.info(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
            except ImportError:
                st.error("âŒ PyTorch åº“æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½ PyTorch Hub æ¨¡å‹")
                return
            
            kwargs = {'pretrained': pretrained} if pretrained else {}
            
            # æ˜¾ç¤ºä¸‹è½½å‚æ•°
            st.info(f"ğŸ“‹ ä¸‹è½½å‚æ•°: repo={repo}, model={model_name}, kwargs={kwargs}")
            
            with st.spinner(f"æ­£åœ¨ä¸‹è½½ {repo}:{model_name}..."):
                try:
                    success, message, model_id = model_downloader.download_pytorch_hub_model(
                        repo, model_name, model_alias, **kwargs
                    )
                    
                    if success:
                        st.success(f"âœ… {message}")
                        if model_id:
                            st.info(f"ğŸ“‹ æ¨¡å‹ID: {model_id}")
                        st.balloons()
                    else:
                        st.error(f"âŒ {message}")
                        
                except Exception as e:
                    st.error(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    st.exception(e)  # æ˜¾ç¤ºè¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯

def custom_url_download_form():
    """è‡ªå®šä¹‰ URL ä¸‹è½½è¡¨å•"""
    st.markdown("### ğŸ”— è‡ªå®šä¹‰ URL")
    
    with st.form("custom_download_form"):
        url = st.text_input(
            "ä¸‹è½½ URL", 
            placeholder="ä¾‹å¦‚: https://example.com/model.zip",
            help="è¾“å…¥æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½é“¾æ¥"
        )
        
        model_alias = st.text_input(
            "æœ¬åœ°åˆ«å", 
            placeholder="ä¾‹å¦‚: custom_model"
        )
        
        extract = st.checkbox("è‡ªåŠ¨è§£å‹", value=True, help="è‡ªåŠ¨è§£å‹ zip/tar æ–‡ä»¶")
        
        if st.form_submit_button("ğŸš€ å¼€å§‹ä¸‹è½½", use_container_width=True):
            if not url or not model_alias:
                st.error("âŒ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
                return
            
            with st.spinner(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹..."):
                success, message, model_id = model_downloader.download_from_url(
                    url, model_alias, extract
                )
                
                if success:
                    st.success(f"âœ… {message}")
                    st.balloons()
                else:
                    st.error(f"âŒ {message}")

def downloaded_models_interface():
    """å·²ä¸‹è½½æ¨¡å‹ç•Œé¢"""
    st.markdown("## ğŸ“‹ å·²ä¸‹è½½çš„æ¨¡å‹")
    
    downloaded_models = model_downloader.list_downloaded_models()
    
    if not downloaded_models:
        st.info("ğŸ“­ è¿˜æ²¡æœ‰ä¸‹è½½ä»»ä½•æ¨¡å‹")
        return
    
    # è½¬æ¢ä¸º DataFrame
    models_data = []
    for model_id, info in downloaded_models.items():
        models_data.append({
            "ID": model_id,
            "åç§°": info.get('model_name', 'N/A'),
            "æ¥æº": info.get('source', 'N/A'),
            "ç±»å‹": info.get('model_type', 'N/A'),
            "å¤§å°": f"{info.get('total_size', 0) / (1024*1024):.2f} MB",
            "ä¸‹è½½æ—¶é—´": info.get('download_time', 'N/A')[:19] if info.get('download_time') else 'N/A'
        })
    
    df = pd.DataFrame(models_data)
    
    # æ˜¾ç¤ºè¡¨æ ¼
    st.dataframe(df, use_container_width=True)
    
    # åˆ é™¤æ¨¡å‹åŠŸèƒ½
    st.markdown("### ğŸ—‘ï¸ åˆ é™¤æ¨¡å‹")
    
    selected_model = st.selectbox(
        "é€‰æ‹©è¦åˆ é™¤çš„æ¨¡å‹",
        options=list(downloaded_models.keys()),
        format_func=lambda x: f"{downloaded_models[x].get('model_name', x)} ({x})"
    )
    
    if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­æ¨¡å‹", type="secondary"):
        if st.session_state.get('confirm_delete', False):
            success, message = model_downloader.delete_downloaded_model(selected_model)
            if success:
                st.success(f"âœ… {message}")
                st.rerun()
            else:
                st.error(f"âŒ {message}")
            st.session_state.confirm_delete = False
        else:
            st.warning("âš ï¸ ç¡®è®¤åˆ é™¤ï¼Ÿå†æ¬¡ç‚¹å‡»ç¡®è®¤")
            st.session_state.confirm_delete = True

def popular_models_interface():
    """çƒ­é—¨æ¨¡å‹ç•Œé¢"""
    st.markdown("## ğŸŒŸ çƒ­é—¨æ¨¡å‹æ¨è")
    
    popular_models = model_downloader.get_popular_models()
    
    for source, models in popular_models.items():
        st.markdown(f"### {source.title()}")
        
        for model in models:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                if source == "pytorch_hub":
                    # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†åŒ…å«å¤šä¸ªå†’å·çš„æ¨¡å‹å­—ç¬¦ä¸²
                    parts = model.split(":")
                    if len(parts) >= 3:
                        repo = f"{parts[0]}:{parts[1]}"  # repo:version
                        model_name = parts[2]  # model_name
                    else:
                        repo, model_name = model.split(":", 1)  # å‘åå…¼å®¹
                    st.markdown(f"**{model_name}** - `{repo}`")
                else:
                    st.markdown(f"**{model}**")
            
            with col2:
                if st.button(f"ä¸‹è½½", key=f"download_{source}_{model}"):
                    # è®¾ç½®ä¸‹è½½å‚æ•°å¹¶è§¦å‘ä¸‹è½½
                    if source == "huggingface":
                        with st.spinner(f"æ­£åœ¨ä¸‹è½½ {model}..."):
                            success, message, _ = model_downloader.download_huggingface_model(model)
                            if success:
                                st.success(f"âœ… {message}")
                            else:
                                st.error(f"âŒ {message}")
                    # å…¶ä»–æºçš„å¿«é€Ÿä¸‹è½½å¯ä»¥ç±»ä¼¼å®ç°
        
        st.markdown("---")

if __name__ == "__main__":
    main()